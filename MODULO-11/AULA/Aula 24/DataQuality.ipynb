{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":72785,"status":"ok","timestamp":1673793771430,"user":{"displayName":"John","userId":"14018759258860000875"},"user_tz":180},"id":"7hISFl3o4BiI","outputId":"dffb3fbb-4fc7-44f1-8cf5-b9e98377e12e"},"outputs":[{"name":"stdout","output_type":"stream","text":["/bin/bash: line 1: ./ngrok: No such file or directory\n"]},{"name":"stderr","output_type":"stream","text":["/bin/bash: line 1: ./ngrok: No such file or directory\n"]},{"data":{"text/plain":["\" from google.colab import drive\\ndrive.mount('/content/drive') \""]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\" # Instalar a vesão 3.0.3 do PySpark\n","!pip install pyspark==3.0.3\n","\n","# Instalar o NGROK\n","!wget -qnc https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip -n -q ngrok-stable-linux-amd64.zip\n"," \"\"\"\n","# Autenticar a sessão do SparkUI com NGROK\n","!./ngrok authtoken 2KBeQEmmd1YNlQ86GGKf3KFOkb3_6sQH7JEnvEhDxwn9A7WnT\n","get_ipython().system_raw('./ngrok http 4050 &')\n","!sleep 10\n","!curl -s http://localhost:4040/api/tunnels | grep -Po 'public_url\":\"(?=https)\\K[^\"]*'\n","\n","\"\"\" from google.colab import drive\n","drive.mount('/content/drive') \"\"\""]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4532,"status":"ok","timestamp":1673793965165,"user":{"displayName":"John","userId":"14018759258860000875"},"user_tz":180},"id":"pChTa_oC5Mlp","outputId":"678eebbd-2fd9-42b2-99b4-7fecd8d4ef76"},"outputs":[],"source":["\"\"\" !pip install pyspark\n","!pip install pyarrow \"\"\"\n","#!pip install pydeequ\n","#!pip install pyspark\n","import os\n","\n","os.environ['SPARK_VERSION'] = '3.3.0'\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["3.3.0\n"]}],"source":["import pyspark\n","print(pyspark.__version__)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18270,"status":"ok","timestamp":1673794527707,"user":{"displayName":"John","userId":"14018759258860000875"},"user_tz":180},"id":"BEDb-O2Q4W2C","outputId":"09cca75d-6b6c-4560-f0d8-d3010cb275f1"},"outputs":[{"name":"stdout","output_type":"stream","text":["23/10/24 23:32:49 WARN Utils: Your hostname, valdir-G5-5590 resolves to a loopback address: 127.0.1.1; using 192.168.0.43 instead (on interface wlp4s0)\n","23/10/24 23:32:49 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",":: loading settings :: url = jar:file:/home/valdir/Documentos/CURSO_DNC/novo-curso-dnc/dnc/lib/python3.8/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"]},{"name":"stderr","output_type":"stream","text":["Ivy Default Cache set to: /home/valdir/.ivy2/cache\n","The jars for the packages stored in: /home/valdir/.ivy2/jars\n","com.amazon.deequ#deequ added as a dependency\n",":: resolving dependencies :: org.apache.spark#spark-submit-parent-5240a942-c3c9-41d9-b1a2-431c9d4178db;1.0\n","\tconfs: [default]\n","\tfound com.amazon.deequ#deequ;2.0.3-spark-3.3 in central\n","\tfound org.scala-lang#scala-reflect;2.12.10 in central\n","\tfound org.scalanlp#breeze_2.12;0.13.2 in central\n","\tfound org.scalanlp#breeze-macros_2.12;0.13.2 in central\n","\tfound com.github.fommil.netlib#core;1.1.2 in central\n","\tfound net.sf.opencsv#opencsv;2.3 in central\n","\tfound com.github.rwl#jtransforms;2.4.0 in central\n","\tfound junit#junit;4.8.2 in central\n","\tfound org.apache.commons#commons-math3;3.2 in central\n","\tfound org.spire-math#spire_2.12;0.13.0 in central\n","\tfound org.spire-math#spire-macros_2.12;0.13.0 in central\n","\tfound org.typelevel#machinist_2.12;0.6.1 in central\n","\tfound com.chuusai#shapeless_2.12;2.3.2 in central\n","\tfound org.typelevel#macro-compat_2.12;1.1.1 in central\n","\tfound org.slf4j#slf4j-api;1.7.5 in central\n","downloading https://repo1.maven.org/maven2/com/amazon/deequ/deequ/2.0.3-spark-3.3/deequ-2.0.3-spark-3.3.jar ...\n","\t[SUCCESSFUL ] com.amazon.deequ#deequ;2.0.3-spark-3.3!deequ.jar (700ms)\n","downloading https://repo1.maven.org/maven2/org/scala-lang/scala-reflect/2.12.10/scala-reflect-2.12.10.jar ...\n","\t[SUCCESSFUL ] org.scala-lang#scala-reflect;2.12.10!scala-reflect.jar (1865ms)\n","downloading https://repo1.maven.org/maven2/org/scalanlp/breeze_2.12/0.13.2/breeze_2.12-0.13.2.jar ...\n","\t[SUCCESSFUL ] org.scalanlp#breeze_2.12;0.13.2!breeze_2.12.jar (8474ms)\n","downloading https://repo1.maven.org/maven2/org/scalanlp/breeze-macros_2.12/0.13.2/breeze-macros_2.12-0.13.2.jar ...\n","\t[SUCCESSFUL ] org.scalanlp#breeze-macros_2.12;0.13.2!breeze-macros_2.12.jar (1766ms)\n","downloading https://repo1.maven.org/maven2/com/github/fommil/netlib/core/1.1.2/core-1.1.2.jar ...\n","\t[SUCCESSFUL ] com.github.fommil.netlib#core;1.1.2!core.jar (3121ms)\n","downloading https://repo1.maven.org/maven2/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar ...\n","\t[SUCCESSFUL ] net.sf.opencsv#opencsv;2.3!opencsv.jar (408ms)\n","downloading https://repo1.maven.org/maven2/com/github/rwl/jtransforms/2.4.0/jtransforms-2.4.0.jar ...\n","\t[SUCCESSFUL ] com.github.rwl#jtransforms;2.4.0!jtransforms.jar (837ms)\n","downloading https://repo1.maven.org/maven2/org/apache/commons/commons-math3/3.2/commons-math3-3.2.jar ...\n","\t[SUCCESSFUL ] org.apache.commons#commons-math3;3.2!commons-math3.jar (1172ms)\n","downloading https://repo1.maven.org/maven2/org/spire-math/spire_2.12/0.13.0/spire_2.12-0.13.0.jar ...\n","\t[SUCCESSFUL ] org.spire-math#spire_2.12;0.13.0!spire_2.12.jar (5903ms)\n","downloading https://repo1.maven.org/maven2/com/chuusai/shapeless_2.12/2.3.2/shapeless_2.12-2.3.2.jar ...\n","\t[SUCCESSFUL ] com.chuusai#shapeless_2.12;2.3.2!shapeless_2.12.jar(bundle) (2182ms)\n","downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.5/slf4j-api-1.7.5.jar ...\n","\t[SUCCESSFUL ] org.slf4j#slf4j-api;1.7.5!slf4j-api.jar (307ms)\n","downloading https://repo1.maven.org/maven2/junit/junit/4.8.2/junit-4.8.2.jar ...\n","\t[SUCCESSFUL ] junit#junit;4.8.2!junit.jar (417ms)\n","downloading https://repo1.maven.org/maven2/org/spire-math/spire-macros_2.12/0.13.0/spire-macros_2.12-0.13.0.jar ...\n","\t[SUCCESSFUL ] org.spire-math#spire-macros_2.12;0.13.0!spire-macros_2.12.jar (315ms)\n","downloading https://repo1.maven.org/maven2/org/typelevel/machinist_2.12/0.6.1/machinist_2.12-0.6.1.jar ...\n","\t[SUCCESSFUL ] org.typelevel#machinist_2.12;0.6.1!machinist_2.12.jar (248ms)\n","downloading https://repo1.maven.org/maven2/org/typelevel/macro-compat_2.12/1.1.1/macro-compat_2.12-1.1.1.jar ...\n","\t[SUCCESSFUL ] org.typelevel#macro-compat_2.12;1.1.1!macro-compat_2.12.jar (296ms)\n",":: resolution report :: resolve 14093ms :: artifacts dl 28046ms\n","\t:: modules in use:\n","\tcom.amazon.deequ#deequ;2.0.3-spark-3.3 from central in [default]\n","\tcom.chuusai#shapeless_2.12;2.3.2 from central in [default]\n","\tcom.github.fommil.netlib#core;1.1.2 from central in [default]\n","\tcom.github.rwl#jtransforms;2.4.0 from central in [default]\n","\tjunit#junit;4.8.2 from central in [default]\n","\tnet.sf.opencsv#opencsv;2.3 from central in [default]\n","\torg.apache.commons#commons-math3;3.2 from central in [default]\n","\torg.scala-lang#scala-reflect;2.12.10 from central in [default]\n","\torg.scalanlp#breeze-macros_2.12;0.13.2 from central in [default]\n","\torg.scalanlp#breeze_2.12;0.13.2 from central in [default]\n","\torg.slf4j#slf4j-api;1.7.5 from central in [default]\n","\torg.spire-math#spire-macros_2.12;0.13.0 from central in [default]\n","\torg.spire-math#spire_2.12;0.13.0 from central in [default]\n","\torg.typelevel#machinist_2.12;0.6.1 from central in [default]\n","\torg.typelevel#macro-compat_2.12;1.1.1 from central in [default]\n","\t:: evicted modules:\n","\torg.scala-lang#scala-reflect;2.12.1 by [org.scala-lang#scala-reflect;2.12.10] in [default]\n","\torg.scala-lang#scala-reflect;2.12.0 by [org.scala-lang#scala-reflect;2.12.10] in [default]\n","\t---------------------------------------------------------------------\n","\t|                  |            modules            ||   artifacts   |\n","\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n","\t---------------------------------------------------------------------\n","\t|      default     |   17  |   15  |   15  |   2   ||   15  |   15  |\n","\t---------------------------------------------------------------------\n",":: retrieving :: org.apache.spark#spark-submit-parent-5240a942-c3c9-41d9-b1a2-431c9d4178db\n","\tconfs: [default]\n","\t15 artifacts copied, 0 already retrieved (33137kB/117ms)\n"]},{"name":"stdout","output_type":"stream","text":["23/10/24 23:33:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"]},{"name":"stderr","output_type":"stream","text":["Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"]}],"source":["from pyspark.sql import SparkSession\n","\n","import pydeequ\n","\n","spark = (\n","    SparkSession.builder                  \n","      .config('spark.ui.port', '4050')\n","      .config(\"spark.jars.packages\", pydeequ.deequ_maven_coord)\n","      .config(\"spark.jars.excludes\", pydeequ.f2j_maven_coord)\n","      .appName(\"SparkSQL\")\n","      .getOrCreate()\n",")\n"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":4064,"status":"ok","timestamp":1673794577760,"user":{"displayName":"John","userId":"14018759258860000875"},"user_tz":180},"id":"WjfnUAJW7V6r"},"outputs":[],"source":["from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType, StringType, TimestampType\n","from pyspark.sql.functions import col\n","\n","schema_remetente_destinatario = StructType([\n","    StructField('nome', StringType()),\n","    StructField('banco', StringType()),\n","    StructField('tipo', StringType())\n","])\n","\n","schema_base_pix = StructType([\n","    StructField('id_transacao', IntegerType()),\n","    StructField('valor', DoubleType()),\n","    StructField('remetente', schema_remetente_destinatario),\n","    StructField('destinatario', schema_remetente_destinatario),\n","    StructField('chave_pix', StringType()),\n","    StructField('categoria', StringType()),\n","    StructField('transaction_date', StringType()),\n","    StructField('fraude', IntegerType())\n","])\n","\n","caminho_json = 'case_final.json'\n","\n","df = spark.read.json(\n","    caminho_json,\n","    schema=schema_base_pix,\n","    timestampFormat=\"yyyy-MM-dd HH:mm:ss\"\n",")\n","\n","df = df.withColumn(\n","      'destinatario_nome', col('destinatario').getField('nome')\n","    ).withColumn(\n","      'destinatario_banco', col('destinatario').getField('banco')\n","    ).withColumn(\n","      'destinatario_tipo', col('destinatario').getField('tipo')\n","    ).withColumn(\n","      'remetente_nome', col('remetente').getField('nome')\n","    ).withColumn(\n","      'remetente_banco', col('remetente').getField('banco')\n","    ).withColumn(\n","      'remetente_tipo', col('remetente').getField('tipo')\n",").drop('remetente', 'destinatario')"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":7485,"status":"ok","timestamp":1673794786629,"user":{"displayName":"John","userId":"14018759258860000875"},"user_tz":180},"id":"5J8vTst47llz"},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["from pydeequ.analyzers import AnalysisRunner, AnalyzerContext, ApproxCountDistinct, Completeness, Compliance, Mean, Size\n","\n","\n","analysisResult = (\n","    AnalysisRunner(spark).onData(df)\n","    .addAnalyzer(Size())\n","    .addAnalyzer(Completeness('id_transacao'))\n","    .addAnalyzer(Compliance(\"valor\", \"valor > 0\"))\n","    .run()\n",")\n"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":310,"status":"ok","timestamp":1673794797950,"user":{"displayName":"John","userId":"14018759258860000875"},"user_tz":180},"id":"cMGFEecm8bZr","outputId":"57915435-9f87-4bf5-ba0c-3e87d481e700"},"outputs":[{"data":{"text/plain":["JavaObject id=o107"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["analysisResult"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":740,"status":"ok","timestamp":1673794811566,"user":{"displayName":"John","userId":"14018759258860000875"},"user_tz":180},"id":"efKXOuOT8X7r"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/valdir/Documentos/CURSO_DNC/novo-curso-dnc/dnc/lib/python3.8/site-packages/pyspark/sql/dataframe.py:127: UserWarning: DataFrame constructor is internal. Do not directly use it.\n","  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n"]}],"source":["analysisResult_df = AnalyzerContext.successMetricsAsDataFrame(spark, analysisResult)\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":689,"status":"ok","timestamp":1673794817718,"user":{"displayName":"John","userId":"14018759258860000875"},"user_tz":180},"id":"spFFeUUf8fgB","outputId":"cdffc600-ed92-4dcc-94b5-ccc7bf2c0b3c"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+------------+------------+--------+\n","| entity|    instance|        name|   value|\n","+-------+------------+------------+--------+\n","|Dataset|           *|        Size|100000.0|\n","| Column|id_transacao|Completeness|     1.0|\n","| Column|       valor|  Compliance| 0.99972|\n","+-------+------------+------------+--------+\n","\n"]}],"source":["analysisResult_df.show()"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":15736,"status":"ok","timestamp":1673794908869,"user":{"displayName":"John","userId":"14018759258860000875"},"user_tz":180},"id":"sKdJyDuc8szw"},"outputs":[{"name":"stdout","output_type":"stream","text":["23/10/24 23:35:46 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["from pydeequ.suggestions import ConstraintSuggestionRunner, DEFAULT\n","\n","suggestionResult = ConstraintSuggestionRunner(spark).onData(df).addConstraintRule(DEFAULT()).run()"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":291,"status":"ok","timestamp":1673794916607,"user":{"displayName":"John","userId":"14018759258860000875"},"user_tz":180},"id":"uKdXUlaF80hF","outputId":"7860e69e-54e6-473b-97c8-f77de87413e2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sugestao de Constraint: 'destinatario_nome': 'destinatario_nome' is not null\n","PySpark Code: .isComplete(\"destinatario_nome\")\n","\n","Sugestao de Constraint: 'remetente_nome': 'remetente_nome' has value range 'Jonathan Gonsalves'\n","PySpark Code: .isContainedIn(\"remetente_nome\", [\"Jonathan Gonsalves\"])\n","\n","Sugestao de Constraint: 'remetente_nome': 'remetente_nome' is not null\n","PySpark Code: .isComplete(\"remetente_nome\")\n","\n","Sugestao de Constraint: 'id_transacao': 'id_transacao' is not null\n","PySpark Code: .isComplete(\"id_transacao\")\n","\n","Sugestao de Constraint: 'id_transacao': 'id_transacao' has no negative values\n","PySpark Code: .isNonNegative(\"id_transacao\")\n","\n","Sugestao de Constraint: 'id_transacao': 'id_transacao' is unique\n","PySpark Code: .isUnique(\"id_transacao\")\n","\n","Sugestao de Constraint: 'remetente_banco': 'remetente_banco' has value range 'BTG'\n","PySpark Code: .isContainedIn(\"remetente_banco\", [\"BTG\"])\n","\n","Sugestao de Constraint: 'remetente_banco': 'remetente_banco' is not null\n","PySpark Code: .isComplete(\"remetente_banco\")\n","\n","Sugestao de Constraint: 'categoria': 'categoria' has value range 'transferencia', 'alimentacao', 'vestuario', 'saude', 'lazer', 'educacao', 'outros', 'presentes', 'transporte'\n","PySpark Code: .isContainedIn(\"categoria\", [\"transferencia\", \"alimentacao\", \"vestuario\", \"saude\", \"lazer\", \"educacao\", \"outros\", \"presentes\", \"transporte\"])\n","\n","Sugestao de Constraint: 'categoria': 'categoria' is not null\n","PySpark Code: .isComplete(\"categoria\")\n","\n","Sugestao de Constraint: 'categoria': 'categoria' has value range 'transferencia', 'alimentacao', 'vestuario', 'saude', 'lazer', 'educacao', 'outros', 'presentes' for at least 90.0% of values\n","PySpark Code: .isContainedIn(\"categoria\", [\"transferencia\", \"alimentacao\", \"vestuario\", \"saude\", \"lazer\", \"educacao\", \"outros\", \"presentes\"], lambda x: x >= 0.9, \"It should be above 0.9!\")\n","\n","Sugestao de Constraint: 'remetente_tipo': 'remetente_tipo' has value range 'PF'\n","PySpark Code: .isContainedIn(\"remetente_tipo\", [\"PF\"])\n","\n","Sugestao de Constraint: 'remetente_tipo': 'remetente_tipo' is not null\n","PySpark Code: .isComplete(\"remetente_tipo\")\n","\n","Sugestao de Constraint: 'chave_pix': 'chave_pix' has value range 'email', 'cpf', 'celular', 'aleatoria'\n","PySpark Code: .isContainedIn(\"chave_pix\", [\"email\", \"cpf\", \"celular\", \"aleatoria\"])\n","\n","Sugestao de Constraint: 'chave_pix': 'chave_pix' is not null\n","PySpark Code: .isComplete(\"chave_pix\")\n","\n","Sugestao de Constraint: 'fraude': 'fraude' has value range '0', '1'\n","PySpark Code: .isContainedIn(\"fraude\", [\"0\", \"1\"])\n","\n","Sugestao de Constraint: 'fraude': 'fraude' is not null\n","PySpark Code: .isComplete(\"fraude\")\n","\n","Sugestao de Constraint: 'fraude': 'fraude' has no negative values\n","PySpark Code: .isNonNegative(\"fraude\")\n","\n","Sugestao de Constraint: 'destinatario_tipo': 'destinatario_tipo' has value range 'PJ', 'PF'\n","PySpark Code: .isContainedIn(\"destinatario_tipo\", [\"PJ\", \"PF\"])\n","\n","Sugestao de Constraint: 'destinatario_tipo': 'destinatario_tipo' is not null\n","PySpark Code: .isComplete(\"destinatario_tipo\")\n","\n","Sugestao de Constraint: 'valor': 'valor' is not null\n","PySpark Code: .isComplete(\"valor\")\n","\n","Sugestao de Constraint: 'valor': 'valor' has no negative values\n","PySpark Code: .isNonNegative(\"valor\")\n","\n","Sugestao de Constraint: 'transaction_date': 'transaction_date' is not null\n","PySpark Code: .isComplete(\"transaction_date\")\n","\n","Sugestao de Constraint: 'transaction_date': 'transaction_date' is unique\n","PySpark Code: .isUnique(\"transaction_date\")\n","\n","Sugestao de Constraint: 'destinatario_banco': 'destinatario_banco' has value range 'XP', 'BTG', 'Nubank', 'Itau', 'Caixa', 'C6', 'Bradesco'\n","PySpark Code: .isContainedIn(\"destinatario_banco\", [\"XP\", \"BTG\", \"Nubank\", \"Itau\", \"Caixa\", \"C6\", \"Bradesco\"])\n","\n","Sugestao de Constraint: 'destinatario_banco': 'destinatario_banco' is not null\n","PySpark Code: .isComplete(\"destinatario_banco\")\n","\n"]}],"source":["for sugg in suggestionResult['constraint_suggestions']:\n","  print(f\"Sugestao de Constraint: \\'{sugg['column_name']}\\': {sugg['description']}\")\n","  print(f\"PySpark Code: {sugg['code_for_constraint']}\\n\")"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1673795013425,"user":{"displayName":"John","userId":"14018759258860000875"},"user_tz":180},"id":"8zL_0laj9D4h"},"outputs":[],"source":["from pydeequ.checks import Check, CheckLevel, ConstrainableDataTypes\n","from pydeequ.verification import VerificationResult, VerificationSuite\n","\n","check = Check(spark, CheckLevel.Warning, \"Review Check\")\n","error = Check(spark, CheckLevel.Error, \"Error\")"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":2138,"status":"ok","timestamp":1673795067392,"user":{"displayName":"John","userId":"14018759258860000875"},"user_tz":180},"id":"ACRK8K6s9QmG"},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["checkResult = (\n","    VerificationSuite(spark)\n","      .onData(df)\n","      .addCheck(\n","        check.hasDataType(\"id_transacao\",ConstrainableDataTypes.Integral)\n","        .isNonNegative(\"id_transacao\")\n","        .isComplete(\"id_transacao\") \n","        .isUnique('id_transcao')\n","      )\n","  .run()\n",")"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":350,"status":"ok","timestamp":1673795078428,"user":{"displayName":"John","userId":"14018759258860000875"},"user_tz":180},"id":"mskdjXXH9emi","outputId":"a9998da4-be38-4667-e567-108b420e17b1"},"outputs":[{"name":"stdout","output_type":"stream","text":["+------------+-----------+------------+----------------------------------------------------------------------------------------------------------------------------+-----------------+-----------------------------------------------+\n","|check       |check_level|check_status|constraint                                                                                                                  |constraint_status|constraint_message                             |\n","+------------+-----------+------------+----------------------------------------------------------------------------------------------------------------------------+-----------------+-----------------------------------------------+\n","|Review Check|Warning    |Warning     |AnalysisBasedConstraint(DataType(id_transacao,None),<function1>,Some(<function1>),None)                                     |Success          |                                               |\n","|Review Check|Warning    |Warning     |ComplianceConstraint(Compliance(id_transacao is non-negative,COALESCE(CAST(id_transacao AS DECIMAL(20,10)), 0.0) >= 0,None))|Success          |                                               |\n","|Review Check|Warning    |Warning     |CompletenessConstraint(Completeness(id_transacao,None))                                                                     |Success          |                                               |\n","|Review Check|Warning    |Warning     |UniquenessConstraint(Uniqueness(List(id_transcao),None))                                                                    |Failure          |Input data does not include column id_transcao!|\n","+------------+-----------+------------+----------------------------------------------------------------------------------------------------------------------------+-----------------+-----------------------------------------------+\n","\n"]},{"name":"stderr","output_type":"stream","text":["/home/valdir/Documentos/CURSO_DNC/novo-curso-dnc/dnc/lib/python3.8/site-packages/pyspark/sql/dataframe.py:127: UserWarning: DataFrame constructor is internal. Do not directly use it.\n","  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n"]}],"source":["checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n","checkResult_df.show(truncate=False)"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":1545,"status":"ok","timestamp":1673795135147,"user":{"displayName":"John","userId":"14018759258860000875"},"user_tz":180},"id":"4LN4cCuL9p_b"},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["checkResult = (\n","    VerificationSuite(spark)\n","      .onData(df)\n","      .addCheck(\n","        error\n","          .isContainedIn(\"remetente_tipo\", [\"CNPJ\"])\n","      )\n","  .run()\n",")"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":440,"status":"ok","timestamp":1673795142876,"user":{"displayName":"John","userId":"14018759258860000875"},"user_tz":180},"id":"SJhgcJPz9vGU","outputId":"9f570e19-fea1-4d7c-933d-1c71eda7cc91"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----+-----------+------------+--------------------------------------------------------------------------------------------------------------------------------+-----------------+----------------------------------------------------+\n","|check|check_level|check_status|constraint                                                                                                                      |constraint_status|constraint_message                                  |\n","+-----+-----------+------------+--------------------------------------------------------------------------------------------------------------------------------+-----------------+----------------------------------------------------+\n","|Error|Error      |Error       |ComplianceConstraint(Compliance(remetente_tipo contained in CNPJ,`remetente_tipo` IS NULL OR `remetente_tipo` IN ('CNPJ'),None))|Failure          |Value: 0.0 does not meet the constraint requirement!|\n","+-----+-----------+------------+--------------------------------------------------------------------------------------------------------------------------------+-----------------+----------------------------------------------------+\n","\n"]}],"source":["checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n","checkResult_df.show(truncate=False)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO4j5q4JzTeBFoKCXfVtaXj","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"}},"nbformat":4,"nbformat_minor":0}
