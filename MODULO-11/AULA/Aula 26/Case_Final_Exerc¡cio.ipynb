{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CUrfUdhmyVpV"
   },
   "source": [
    "# Case Final\n",
    "## Análise de Transações PIX\n",
    "CRISP-DM - https://www.escoladnc.com.br/blog/data-science/metodologia-crisp-dm/\n",
    "### Objetivos\n",
    "- Limpar e pré-processar os dados das transações PIX\n",
    "- Analisar padrões de uso do PIX, tais como os canais mais utilizados e os valores de transação mais comuns\n",
    "- Use o PySpark MLlib para treinar e avaliar um modelo de detecção de fraude\n",
    "- Avaliar o desempenho do modelo e fazer recomendações para melhorias futuras\n",
    "\n",
    "### Dados\n",
    "\n",
    "O conjunto de dados inclui as seguintes informações para cada transação:\n",
    "- Detalhes da transação: valor, tempo, remetente e receptor CPF/CNPJ, tipo\n",
    "- Etiqueta de fraude: uma variável binária que indica se a transação foi fraudulenta (1) ou não (0)\n",
    "\n",
    "### Tarefas\n",
    "- Normalização dos dados:\n",
    "  - O dataset que você lerá está em formato json.\n",
    "  ```json\n",
    "  {\n",
    "      \"id_transacao\": inteiro,\n",
    "      \"valor\": texto,\n",
    "      \"remetente\": {\n",
    "          \"nome\": texto,\n",
    "          \"banco\": texto,\n",
    "          \"tipo\": texto\n",
    "      },\n",
    "      \"destinatario\": {\n",
    "          \"nome\": texto,\n",
    "          \"banco\":texto,\n",
    "          \"tipo\": texto\n",
    "      },          \n",
    "      \"categoria\":texto,\n",
    "      \"chave_pix\":texto,\n",
    "      \"transaction_date\":texto,\n",
    "      \"fraude\":inteiro,\n",
    "  }\n",
    "    ```\n",
    "  - Faça sua transformação para formato colunar\n",
    "- Análise Exploratória de Dados: Use o PySpark para analisar padrões de uso do PIX:\n",
    "  - chaves pix mais usadas;\n",
    "  - os valores de transação mais comuns;\n",
    "  - distribuição dos valores de transação por hora e dia;\n",
    "  - quais bancos receberam mais transferências por dia;\n",
    "  - para qual tipo de pessoa (PF ou PJ) foram realizadas mais transações\n",
    "- Engenharia de Recursos: Apresentar novas características que podem ser úteis para a detecção de fraudes, tais como o número de transações feitas pelo mesmo remetente em um período de tempo específico.\n",
    "- Modelagem: Use o PySpark MLlib para treinar e detectar possíveis transações que contenham fraude.\n",
    "\n",
    "### Observação\n",
    "É importante notar que este é um caso simplificado, e em cenários do mundo real você teria que lidar com dados mais complexos, usar técnicas mais avançadas como métodos de conjuntos e considerar o conhecimento de domínio, bem como leis e regulamentos das instituições financeiras no Brasil.\n",
    "\n",
    "\n",
    "### Observação II\n",
    "Não existe resposta 100% correta. É necessário que você use seu pensamento crítico para definir as melhores métricas e análises para o caso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qEUukChAJ1t"
   },
   "source": [
    "# Entendimento do Negócio\n",
    "Você trabalha em um banco e o principal meio de pagamento utilizado no seu banco é o Pix.\n",
    "\n",
    "Através da base de transações do pix o banco deseja entender qual é o perfil dos clientes que utilizam o pix, além de verificar possíveis transações que tenham fraude. Porém, eles tem um cliente específico que tem um relacionamento muito bom para o banco, por isso, você recebeu a base de transações de cliente dos últimos 2 anos e precisa a partir dela criar um relatório contendo as principais características das transações.\n",
    "\n",
    "\n",
    "Então, resumindo, temos dois principais objetivos para esse case:\n",
    "1. Obter valor a partir dos dados\n",
    "  - Para qual banco esse cliente mais transfere?\n",
    "  - Qual é a média de transferências por período que esse cliente faz?\n",
    "  - Baseando-se no valor das transferências, poderia dar um aumento de crédito?\n",
    "  - Para o que esse cliente mais usa as transferências?\n",
    "2. Executar um algoritmo de machine learning que identifique possíveis transações com fraude.\n",
    "3. Pós Processamento\n",
    "  - Defina ao mínimo cinco métricas de qualidade para seus dados\n",
    "  - Explique se os seus dados estão com uma boa qualidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fpXPtmLKKxnk"
   },
   "source": [
    "# Preparação do Ambiente de Desenvolvimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tj4_a-elAgQa",
    "outputId": "f8c6b474-790e-4dd9-9001-782418508b06"
   },
   "outputs": [],
   "source": [
    "# !pip install pyspark\n",
    "# !pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "6JDgBGfy_Ojy",
    "outputId": "51700a4e-9b55-4aa9-c58b-925953c61d23"
   },
   "outputs": [],
   "source": [
    "# Importar bibliotecas e preparar todo o processo de seleção dos dados com spark\n",
    "# Importar bibliotecas\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "# from pyspark.ml import Pipeline\n",
    "# from pyspark.ml.feature import \n",
    "# from google.colab import files\n",
    "\n",
    "# upload = files.upload()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zsNxOI_v_Oj1",
    "outputId": "695a8b74-703a-4f9b-91d4-7eccf01f35b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authtoken saved to configuration file: /home/valdir/.ngrok2/ngrok.yml\n",
      "https://cdb8-2804-88c-4d3b-d200-2391-96b5-7aa-8632.ngrok-free.app\n"
     ]
    }
   ],
   "source": [
    "# Autenticar a sessão do SparkUI com NGROK\n",
    "!./ngrok authtoken 2Wlm9bDY0eka79Pd7tED4KnBUZv_24dzLdjRdSZXTLHaKUxpS\n",
    "get_ipython().system_raw('./ngrok http 4050 &')\n",
    "!sleep 10\n",
    "!curl -s http://localhost:4040/api/tunnels | grep -Po 'public_url\":\"(?=https)\\K[^\"]*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "t_eBKSpD_Oj4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/02 12:53:39 WARN Utils: Your hostname, valdir-G5-5590 resolves to a loopback address: 127.0.1.1; using 192.168.0.43 instead (on interface wlp4s0)\n",
      "23/11/02 12:53:39 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/02 12:53:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "#iniciar sessão spark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .config('spark.ui.port', '4050')\n",
    "    .appName('Case_Final').getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "5PgZfJdy_Oj5"
   },
   "outputs": [],
   "source": [
    "# carregar os dados\n",
    "schema_remetente_destinatario = StructType([\n",
    "    StructField('nome', StringType()),\n",
    "    StructField('banco', StringType()),\n",
    "    StructField('tipo', StringType()),\n",
    "])\n",
    "\n",
    "schema_base_pix = StructType([\n",
    "    StructField(\"id_transacao\", IntegerType()),\n",
    "    StructField(\"valor\", DoubleType()),\n",
    "    StructField(\"data\", StringType()),\n",
    "    StructField('remetente', schema_remetente_destinatario),\n",
    "    StructField('destinatario', schema_remetente_destinatario),\n",
    "    StructField('chave_pix', StringType()),\n",
    "    StructField('categoria', StringType()),\n",
    "    StructField('transaction_date', StringType()),\n",
    "    StructField('fraude', IntegerType())\n",
    "])\n",
    "\n",
    "df = spark.read.json(\n",
    "    'case_final.json',\n",
    "    schema=schema_base_pix,\n",
    "    timestampFormat='yyyy-MM-dd HH:mm:ss',\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3O2L-qD9_Oj6",
    "outputId": "7d6a8cd2-1e1e-4ff8-bafd-ede3e3b56f8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_transacao: integer (nullable = true)\n",
      " |-- valor: double (nullable = true)\n",
      " |-- data: string (nullable = true)\n",
      " |-- remetente: struct (nullable = true)\n",
      " |    |-- nome: string (nullable = true)\n",
      " |    |-- banco: string (nullable = true)\n",
      " |    |-- tipo: string (nullable = true)\n",
      " |-- destinatario: struct (nullable = true)\n",
      " |    |-- nome: string (nullable = true)\n",
      " |    |-- banco: string (nullable = true)\n",
      " |    |-- tipo: string (nullable = true)\n",
      " |-- chave_pix: string (nullable = true)\n",
      " |-- categoria: string (nullable = true)\n",
      " |-- transaction_date: string (nullable = true)\n",
      " |-- fraude: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "rDAMm9PB_Oj6",
    "outputId": "9fcc329f-809c-4c20-8fc0-12975404c7db"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFBKW-UUAMOo"
   },
   "source": [
    "# Data Undesrtanting\n",
    "\n",
    "Primeiramente, devemos entender tudo sobre a fonte dos dados\n",
    "- Como o dado chega até nós?\n",
    "- Qual formato virá?\n",
    "- Aonde o processamento será executado (AWS EMR, Cluster On-Premise)?\n",
    "- De quanto em quanto tempo eu preciso gerar esse relatório (mensal, diário, near-real time)?\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id_transacao\": inteiro,\n",
    "  \"valor\": texto,\n",
    "  \"remetente\": {\n",
    "      \"nome\": texto,\n",
    "      \"banco\": texto,\n",
    "      \"tipo\": texto\n",
    "  },\n",
    "  \"destinatario\": {\n",
    "      \"nome\": texto,\n",
    "      \"banco\":texto,\n",
    "      \"tipo\": texto\n",
    "  },\n",
    "  \"categoria\": texto,\n",
    "  \"transaction_date\":texto,\n",
    "  \"chave_pix\":texto,\n",
    "  \"fraude\":inteiro,\n",
    "}\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KPvcwRICAPod"
   },
   "source": [
    "# Preparação dos Dados\n",
    "Agora é hora de começar a preparar os dados de acordo com as suas necessidades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tnOJ5pwHARTD"
   },
   "source": [
    "# Modelagem\n",
    "Aqui você encontrará utilidade para os dados levantados.\n",
    "\n",
    "Aqui será onde teremos insights e, a partir desses, novos conhecimentos sobre o business (se tudo até aqui foi feito corretamente).\n",
    "\n",
    "\n",
    "- Para qual banco esse cliente mais transfere?\n",
    "- Qual é a média de transferências por período que esse cliente faz?\n",
    "- Baseando-se no valor das transferências, poderia dar um aumento de crédito?\n",
    "- Para o que esse cliente mais usa as transferências?\n",
    "- Executar um algoritmo de machine learning que identifique possíveis transações com fraude.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "6Rw-jLCW_Oj8"
   },
   "outputs": [],
   "source": [
    "#transformar remetenete e destinatario em colunas\n",
    "df = df.withColumn('nome_remetente', df.remetente.nome)\n",
    "df = df.withColumn('banco_remetente', df.remetente.banco)\n",
    "df = df.withColumn('tipo_remetente', df.remetente.tipo)\n",
    "df = df.withColumn('nome_destinatario', df.destinatario.nome)\n",
    "df = df.withColumn('banco_destinatario', df.destinatario.banco)\n",
    "df = df.withColumn('tipo_destinatario', df.destinatario.tipo).drop('remetente', 'destinatario')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9GnzRZ-p_Oj8",
    "outputId": "a32d0a74-c2eb-4fa7-d733-f341228416dc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+------+---------+---------+----------------+------+--------------+---------------+--------------+-----------------+------------------+-----------------+\n",
      "|id_transacao|valor|  data|chave_pix|categoria|transaction_date|fraude|nome_remetente|banco_remetente|tipo_remetente|nome_destinatario|banco_destinatario|tipo_destinatario|\n",
      "+------------+-----+------+---------+---------+----------------+------+--------------+---------------+--------------+-----------------+------------------+-----------------+\n",
      "|           0|    0|100000|        0|        0|               0|     0|             0|              0|             0|                0|                 0|                0|\n",
      "+------------+-----+------+---------+---------+----------------+------+--------------+---------------+--------------+-----------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificar se existem valores nulos\n",
    "df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8UfC97HP_Oj9",
    "outputId": "a97a9137-56b3-4567-a6cb-cd38436983b0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:===================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "|banco_destinatario|count|\n",
      "+------------------+-----+\n",
      "|                XP|14401|\n",
      "|               BTG|14390|\n",
      "|            Nubank|14297|\n",
      "|              Itau|14281|\n",
      "|             Caixa|14240|\n",
      "|                C6|14204|\n",
      "|          Bradesco|14187|\n",
      "+------------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Para qual banco esse cliente mais transfere?\n",
    "\n",
    "df.groupBy('banco_destinatario').count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "LjxAUYks_Oj-",
    "outputId": "1c62f9a5-8aa5-4260-8562-6369defa309f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:===================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|    mes|count|\n",
      "+-------+-----+\n",
      "|2021-01| 2415|\n",
      "|2021-02| 3794|\n",
      "|2021-03| 4179|\n",
      "|2021-04| 4061|\n",
      "|2021-05| 4303|\n",
      "|2021-06| 4238|\n",
      "|2021-07| 4159|\n",
      "|2021-08| 4250|\n",
      "|2021-09| 4096|\n",
      "|2021-10| 4234|\n",
      "|2021-11| 4050|\n",
      "|2021-12| 4232|\n",
      "|2022-01| 4239|\n",
      "|2022-02| 3855|\n",
      "|2022-03| 4283|\n",
      "|2022-04| 4108|\n",
      "|2022-05| 4241|\n",
      "|2022-06| 4091|\n",
      "|2022-07| 4336|\n",
      "|2022-08| 4228|\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Qual é a média de transferências por período que esse cliente faz?\n",
    "df.groupBy(date_format(col('transaction_date'), 'yyyy-MM').alias('mes')).count().orderBy('mes').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "oJfdpUC9_Oj-",
    "outputId": "22f6b42f-4e79-4734-be37-af4d497b97ca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:==================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "| ano|count|\n",
      "+----+-----+\n",
      "|2021|48011|\n",
      "|2022|50030|\n",
      "|2023| 1959|\n",
      "+----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.groupBy(date_format(col('transaction_date'), 'yyyy').alias('ano')).count().orderBy('ano').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "85yEJ3-F_Oj_",
    "outputId": "e97bdf62-3d25-4dba-ed70-43502b5aa900"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:==================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "| ano|        avg(valor)|\n",
      "+----+------------------+\n",
      "|2022|10265.353683190187|\n",
      "|2023|10002.365324144983|\n",
      "|2021|10355.243481285566|\n",
      "+----+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "df.groupBy(date_format(col('transaction_date'),'yyyy').alias('ano')).agg(avg('valor')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "NEDPw7qT_Oj_",
    "outputId": "649ce51c-640b-4d74-f2cf-91ed0ba4dc24"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:==================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+\n",
      "|    categoria|             media|\n",
      "+-------------+------------------+\n",
      "|transferencia|34877.567212657654|\n",
      "|    presentes|2287.6823222390217|\n",
      "|    vestuario|2269.6187635483498|\n",
      "|   transporte|2232.2969587966013|\n",
      "|       outros| 2218.729851764958|\n",
      "|  alimentacao| 2217.824653330547|\n",
      "|     educacao|2209.8863816067596|\n",
      "|        saude|2198.5639014351987|\n",
      "|        lazer|2154.2605853761643|\n",
      "+-------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Para o que esse cliente mais usa as transferências?\n",
    "df.groupBy('categoria').agg(avg('valor').alias('media')).orderBy('media', ascending=False).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "1OXYubIS_Oj_",
    "outputId": "38d770fa-37f8-4ca5-ce01-673881a8f933"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:==================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+\n",
      "|banco_destinatario|          sum(valor)|\n",
      "+------------------+--------------------+\n",
      "|          Bradesco|1.4987422862999955E8|\n",
      "|                XP|1.4873455870999998E8|\n",
      "|            Nubank| 1.474946488100003E8|\n",
      "|                C6| 1.464361347999994E8|\n",
      "|              Itau|1.4610714452000046E8|\n",
      "|             Caixa| 1.460292635799994E8|\n",
      "|               BTG| 1.456598941699996E8|\n",
      "+------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# # Baseando-se no valor das transferências, poderia dar um aumento de crédito?\n",
    "df.groupBy('banco_destinatario').sum('valor').orderBy('sum(valor)', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "O-rlJSi4_OkA",
    "outputId": "7dda6c00-f7aa-4f24-8b3b-db6443051187"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/02 12:54:13 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 24:==================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+----+---------+-----------+-------------------+------------------+------------------+---------------+--------------+-----------------+------------------+-----------------+\n",
      "|summary|     id_transacao|             valor|data|chave_pix|  categoria|   transaction_date|            fraude|    nome_remetente|banco_remetente|tipo_remetente|nome_destinatario|banco_destinatario|tipo_destinatario|\n",
      "+-------+-----------------+------------------+----+---------+-----------+-------------------+------------------+------------------+---------------+--------------+-----------------+------------------+-----------------+\n",
      "|  count|           100000|            100000|   0|   100000|     100000|             100000|            100000|            100000|         100000|        100000|           100000|            100000|           100000|\n",
      "|   mean|          50999.5|10303.358732200059|NULL|     NULL|       NULL|               NULL|           0.15367|              NULL|           NULL|          NULL|             NULL|              NULL|             NULL|\n",
      "| stddev|28867.65779668774| 20874.99768875586|NULL|     NULL|       NULL|               NULL|0.3606339302787737|              NULL|           NULL|          NULL|             NULL|              NULL|             NULL|\n",
      "|    min|             1000|               0.0|NULL|aleatoria|alimentacao|2021-01-14 15:37:45|                 0|Jonathan Gonsalves|            BTG|            PF|   Agatha Almeida|               BTG|               PF|\n",
      "|    max|           100999|          89996.33|NULL|    email|  vestuario|2023-01-15 02:51:10|                 1|Jonathan Gonsalves|            BTG|            PF|   Yuri das Neves|                XP|               PJ|\n",
      "+-------+-----------------+------------------+----+---------+-----------+-------------------+------------------+------------------+---------------+--------------+-----------------+------------------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f0okoh9K_OkA",
    "outputId": "c182883f-0e7a-4503-dd96-ede8e8808d03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_transacao: integer (nullable = true)\n",
      " |-- valor: double (nullable = true)\n",
      " |-- data: string (nullable = true)\n",
      " |-- chave_pix: string (nullable = true)\n",
      " |-- categoria: string (nullable = true)\n",
      " |-- transaction_date: string (nullable = true)\n",
      " |-- fraude: integer (nullable = true)\n",
      " |-- nome_remetente: string (nullable = true)\n",
      " |-- banco_remetente: string (nullable = true)\n",
      " |-- tipo_remetente: string (nullable = true)\n",
      " |-- nome_destinatario: string (nullable = true)\n",
      " |-- banco_destinatario: string (nullable = true)\n",
      " |-- tipo_destinatario: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfml =  df.drop('remetente', 'id_transacao')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "id": "xOmsMSTZ_OkB",
    "outputId": "9317c8b9-fc39-4288-cc33-8be058ea9efc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Executar um algoritmo de machine learning que identifique possíveis transações com fraude.  (Opcional)\n",
    "\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# 1.1 - Cria o objeto StringIndexer\n",
    "indexer = StringIndexer(\n",
    "    inputCols=[\n",
    "        \"categoria\",\n",
    "        \"banco_destinatario\",\n",
    "        \"nome_destinatario\",\n",
    "        \"tipo_destinatario\",\n",
    "        \"chave_pix\"\n",
    "    ],\n",
    "    outputCols=[\n",
    "        \"categoria_index\",\n",
    "        \"banco_destinatario_index\",\n",
    "        \"nome_destinatario_index\",\n",
    "        \"tipo_destinatario_index\",\n",
    "        \"chave_pix_index\"\n",
    "    ]\n",
    "\n",
    "    )\n",
    "# Treina o StringIndexer\n",
    "si = indexer.fit(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indexer = si.transform(dfml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/02 12:54:25 WARN DAGScheduler: Broadcasting large task binary with size 1278.6 KiB\n",
      "[Stage 30:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----+---------+-------------+-------------------+------+------------------+---------------+--------------+--------------------+------------------+-----------------+---------------+------------------------+-----------------------+-----------------------+---------------+\n",
      "|             valor|data|chave_pix|    categoria|   transaction_date|fraude|    nome_remetente|banco_remetente|tipo_remetente|   nome_destinatario|banco_destinatario|tipo_destinatario|categoria_index|banco_destinatario_index|nome_destinatario_index|tipo_destinatario_index|chave_pix_index|\n",
      "+------------------+----+---------+-------------+-------------------+------+------------------+---------------+--------------+--------------------+------------------+-----------------+---------------+------------------------+-----------------------+-----------------------+---------------+\n",
      "|            588.08|NULL|aleatoria|       outros|2021-07-16 05:00:55|     0|Jonathan Gonsalves|            BTG|            PF|         Calebe Melo|             Caixa|               PF|            6.0|                     4.0|                12045.0|                    1.0|            3.0|\n",
      "|           80682.5|NULL|  celular|transferencia|2022-04-20 12:34:01|     1|Jonathan Gonsalves|            BTG|            PF|  Davi Lucas Pereira|             Caixa|               PJ|            0.0|                     4.0|                  259.0|                    0.0|            2.0|\n",
      "|             549.9|NULL|      cpf|        lazer|2022-07-10 16:51:34|     0|Jonathan Gonsalves|            BTG|            PF|      Sabrina Castro|            Nubank|               PF|            4.0|                     2.0|                  132.0|                    1.0|            1.0|\n",
      "|             90.83|NULL|aleatoria|   transporte|2022-10-20 10:57:36|     0|Jonathan Gonsalves|            BTG|            PF|Francisco da Conc...|            Nubank|               PJ|            8.0|                     2.0|                10475.0|                    0.0|            3.0|\n",
      "|13272.619999999999|NULL|    email|transferencia|2021-04-06 20:26:51|     0|Jonathan Gonsalves|            BTG|            PF|   Isabelly Ferreira|               BTG|               PJ|            0.0|                     1.0|                 4159.0|                    0.0|            0.0|\n",
      "|           9347.58|NULL|aleatoria|        saude|2022-07-24 15:22:27|     0|Jonathan Gonsalves|            BTG|            PF|Srta. Maria da Cunha|              Itau|               PJ|            3.0|                     3.0|                26853.0|                    0.0|            3.0|\n",
      "|           7836.76|NULL|      cpf|    presentes|2022-10-05 19:20:24|     0|Jonathan Gonsalves|            BTG|            PF|     Catarina Duarte|                C6|               PF|            7.0|                     5.0|                 5578.0|                    1.0|            1.0|\n",
      "|           3883.62|NULL|      cpf|    vestuario|2021-04-24 17:36:34|     0|Jonathan Gonsalves|            BTG|            PF|       Vitor Correia|                XP|               PJ|            2.0|                     0.0|                13528.0|                    0.0|            1.0|\n",
      "|               4.0|NULL|aleatoria|        saude|2021-11-16 21:46:47|     0|Jonathan Gonsalves|            BTG|            PF|         Theo Novaes|                C6|               PJ|            3.0|                     5.0|                 1141.0|                    0.0|            3.0|\n",
      "|              24.3|NULL|      cpf|transferencia|2021-07-26 02:08:49|     0|Jonathan Gonsalves|            BTG|            PF|     Isabel Caldeira|                XP|               PJ|            0.0|                     0.0|                 8369.0|                    0.0|            1.0|\n",
      "|           87555.3|NULL|aleatoria|transferencia|2022-03-14 15:34:45|     1|Jonathan Gonsalves|            BTG|            PF|Sr. Henrique Cardoso|            Nubank|               PF|            0.0|                     2.0|                22115.0|                    1.0|            3.0|\n",
      "|          21345.91|NULL|      cpf|transferencia|2021-10-31 04:31:51|     1|Jonathan Gonsalves|            BTG|            PF|   Felipe Cavalcanti|            Nubank|               PJ|            0.0|                     2.0|                 5897.0|                    0.0|            1.0|\n",
      "|          73605.85|NULL|  celular|transferencia|2021-04-30 19:19:56|     1|Jonathan Gonsalves|            BTG|            PF|     Dr. Davi da Luz|          Bradesco|               PJ|            0.0|                     6.0|                12212.0|                    0.0|            2.0|\n",
      "|             93.53|NULL|      cpf|  alimentacao|2023-01-13 13:39:57|     0|Jonathan Gonsalves|            BTG|            PF|    Stephany Cardoso|                C6|               PJ|            1.0|                     5.0|                   10.0|                    0.0|            1.0|\n",
      "|            564.11|NULL|aleatoria|    vestuario|2022-05-27 23:06:08|     0|Jonathan Gonsalves|            BTG|            PF|   Sra. Julia Araujo|              Itau|               PJ|            2.0|                     3.0|                24413.0|                    0.0|            3.0|\n",
      "|              3.59|NULL|    email|        saude|2021-10-06 21:19:58|     0|Jonathan Gonsalves|            BTG|            PF|     Carolina Farias|            Nubank|               PJ|            3.0|                     2.0|                10121.0|                    0.0|            0.0|\n",
      "|          19164.89|NULL|    email|  alimentacao|2022-03-06 17:59:43|     0|Jonathan Gonsalves|            BTG|            PF|   Isabelly da Costa|            Nubank|               PJ|            1.0|                     2.0|                 6122.0|                    0.0|            0.0|\n",
      "|             68.45|NULL|aleatoria|    vestuario|2022-04-01 18:17:40|     0|Jonathan Gonsalves|            BTG|            PF|Joao Miguel Silveira|                C6|               PJ|            2.0|                     5.0|                 6214.0|                    0.0|            3.0|\n",
      "|            941.25|NULL|  celular|    vestuario|2022-05-23 00:28:13|     0|Jonathan Gonsalves|            BTG|            PF|       Matheus Moura|                C6|               PF|            2.0|                     5.0|                 1829.0|                    1.0|            2.0|\n",
      "|27009.910000000003|NULL|    email|transferencia|2021-08-04 23:22:37|     1|Jonathan Gonsalves|            BTG|            PF| Gabrielly Goncalves|              Itau|               PJ|            0.0|                     3.0|                 5973.0|                    0.0|            0.0|\n",
      "+------------------+----+---------+-------------+-------------------+------+------------------+---------------+--------------+--------------------+------------------+-----------------+---------------+------------------------+-----------------------+-----------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_indexer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_para_filtrar = [\n",
    "    'valor',\n",
    "    'transaction_date',\n",
    "    \"categoria_index\",\n",
    "    \"banco_destinatario_index\",\n",
    "    \"nome_destinatario_index\",\n",
    "    \"tipo_destinatario_index\",\n",
    "    \"chave_pix_index\",\n",
    "    'fraude'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_fraude = df_indexer.select(cols_para_filtrar).filter('fraude == 1')\n",
    "no_fraude = df_indexer.select(cols_para_filtrar).filter('fraude == 0')\n",
    "no_fraude =  no_fraude.sample(False, 0.01, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16202"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat = no_fraude.union(is_fraude)\n",
    "dfml = df_concat.sort(\"transaction_date\")\n",
    "dfml.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/02 12:54:30 WARN DAGScheduler: Broadcasting large task binary with size 1289.9 KiB\n",
      "23/11/02 12:54:33 WARN DAGScheduler: Broadcasting large task binary with size 1290.5 KiB\n",
      "23/11/02 12:54:34 WARN DAGScheduler: Broadcasting large task binary with size 1302.2 KiB\n",
      "23/11/02 12:54:37 WARN DAGScheduler: Broadcasting large task binary with size 1296.9 KiB\n",
      "23/11/02 12:54:38 WARN DAGScheduler: Broadcasting large task binary with size 1289.9 KiB\n",
      "23/11/02 12:54:41 WARN DAGScheduler: Broadcasting large task binary with size 1290.5 KiB\n",
      "23/11/02 12:54:42 WARN DAGScheduler: Broadcasting large task binary with size 1302.2 KiB\n",
      "23/11/02 12:54:45 WARN DAGScheduler: Broadcasting large task binary with size 1296.9 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 11278 Test 4924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "treino, teste =  dfml.randomSplit([0.70,0.30], seed = 123)\n",
    "print(f\"Train {treino.count()}\", f\"Test {teste.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_fraude = udf(lambda fraude: 1.0 if fraude >0 else 0.0, DoubleType())\n",
    "treino = treino.withColumn(\"is_fraude\", is_fraude(treino.fraude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/02 12:54:47 WARN DAGScheduler: Broadcasting large task binary with size 1289.9 KiB\n",
      "23/11/02 12:54:49 WARN DAGScheduler: Broadcasting large task binary with size 1290.5 KiB\n",
      "23/11/02 12:54:50 WARN DAGScheduler: Broadcasting large task binary with size 1302.2 KiB\n",
      "23/11/02 12:54:53 WARN DAGScheduler: Broadcasting large task binary with size 1289.9 KiB\n",
      "23/11/02 12:54:55 WARN DAGScheduler: Broadcasting large task binary with size 1290.5 KiB\n",
      "23/11/02 12:54:56 WARN DAGScheduler: Broadcasting large task binary with size 1302.2 KiB\n",
      "23/11/02 12:54:59 WARN DAGScheduler: Broadcasting large task binary with size 1340.9 KiB\n",
      "23/11/02 12:55:06 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "23/11/02 12:55:08 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "23/11/02 12:55:08 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "23/11/02 12:55:08 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "23/11/02 12:55:09 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "23/11/02 12:55:09 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "23/11/02 12:55:09 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "23/11/02 12:55:09 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "23/11/02 12:55:10 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "23/11/02 12:55:10 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "23/11/02 12:55:10 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "23/11/02 12:55:10 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "23/11/02 12:55:10 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "23/11/02 12:55:11 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "23/11/02 12:55:11 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "23/11/02 12:55:11 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "23/11/02 12:55:11 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "23/11/02 12:55:11 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "23/11/02 12:55:12 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "23/11/02 12:55:12 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "23/11/02 12:55:12 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "23/11/02 12:55:12 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "23/11/02 12:55:12 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "23/11/02 12:55:13 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "23/11/02 12:55:13 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "23/11/02 12:55:13 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "23/11/02 12:55:13 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "23/11/02 12:55:13 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "23/11/02 12:55:14 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "23/11/02 12:55:14 WARN DAGScheduler: Broadcasting large task binary with size 1341.6 KiB\n",
      "23/11/02 12:55:15 WARN DAGScheduler: Broadcasting large task binary with size 1289.9 KiB\n",
      "23/11/02 12:55:18 WARN DAGScheduler: Broadcasting large task binary with size 1290.5 KiB\n",
      "23/11/02 12:55:20 WARN DAGScheduler: Broadcasting large task binary with size 1302.2 KiB\n",
      "23/11/02 12:55:24 WARN DAGScheduler: Broadcasting large task binary with size 1289.9 KiB\n",
      "23/11/02 12:55:26 WARN DAGScheduler: Broadcasting large task binary with size 1290.5 KiB\n",
      "23/11/02 12:55:28 WARN DAGScheduler: Broadcasting large task binary with size 1302.2 KiB\n",
      "[Stage 123:================================================>      (14 + 2) / 16]\r"
     ]
    }
   ],
   "source": [
    "# criar os vetores de recursos.\n",
    "# VectorAssembler é um transformador que combina uma determinada lista de colunas em uma única coluna de vetor.\n",
    "assembler = VectorAssembler(\n",
    "  inputCols = [x for x in treino.columns if x not in [\"transaction_date\", \"fraude\", \"is_fraude\"]],\n",
    "  outputCol = \"features\")\n",
    "\n",
    "# Use Logistic Regression.\n",
    "# is a machine learning algorithm that is used for classification tasks\n",
    "lr = LogisticRegression().setParams(\n",
    "    maxIter = 100000,\n",
    "    labelCol = \"is_fraude\",\n",
    "    predictionCol = \"prediction\")\n",
    "\n",
    "\n",
    "# This will train a logistic regression model on the input data and return a \n",
    "# LogisticRegressionModel object which can be used to make predictions on new data.\n",
    "model = Pipeline(stages = [assembler, lr]).fit(treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/02 12:56:05 WARN DAGScheduler: Broadcasting large task binary with size 1289.9 KiB\n",
      "23/11/02 12:56:07 WARN DAGScheduler: Broadcasting large task binary with size 1290.5 KiB\n",
      "23/11/02 12:56:08 WARN DAGScheduler: Broadcasting large task binary with size 1302.2 KiB\n",
      "23/11/02 12:56:10 WARN DAGScheduler: Broadcasting large task binary with size 1339.9 KiB\n",
      "23/11/02 12:56:10 WARN DAGScheduler: Broadcasting large task binary with size 1330.6 KiB\n",
      "23/11/02 12:56:10 WARN DAGScheduler: Broadcasting large task binary with size 1330.3 KiB\n",
      "23/11/02 12:56:10 WARN DAGScheduler: Broadcasting large task binary with size 1328.0 KiB\n",
      "23/11/02 12:56:11 WARN DAGScheduler: Broadcasting large task binary with size 1289.9 KiB\n",
      "23/11/02 12:56:12 WARN DAGScheduler: Broadcasting large task binary with size 1290.5 KiB\n",
      "23/11/02 12:56:13 WARN DAGScheduler: Broadcasting large task binary with size 1302.2 KiB\n",
      "23/11/02 12:56:16 WARN DAGScheduler: Broadcasting large task binary with size 1346.7 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+----+\n",
      "|is_fraude_prediction|0.0| 1.0|\n",
      "+--------------------+---+----+\n",
      "|                 1.0|  0|4660|\n",
      "|                 0.0|262|   2|\n",
      "+--------------------+---+----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/02 12:56:16 WARN DAGScheduler: Broadcasting large task binary with size 1334.5 KiB\n",
      "23/11/02 12:56:16 WARN DAGScheduler: Broadcasting large task binary with size 1337.8 KiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predicted = model.transform(teste)\n",
    "predicted = predicted.withColumn(\"is_fraude\", is_fraude(predicted.fraude))\n",
    "predicted.crosstab(\"is_fraude\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zHoQJWtATfX"
   },
   "source": [
    "# Avaliação do Modelo\n",
    "Será que seu modelo atinge todas as necessidades que foram definidas inicialmente? (e.g. pessoa em cima da bicicleta muda o resultado final)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOTAB1JSAVPi"
   },
   "source": [
    "# Deployment\n",
    "Apresente o relatório com os resultados obtidos.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
